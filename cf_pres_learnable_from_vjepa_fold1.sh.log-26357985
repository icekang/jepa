/home/gridsan/nchutisilp/.conda/envs/jepa/bin/python
INFO:root:called-params configs/evals/vitl16_cf_pres_16x2x3_from_vjepa_fold1.yaml
INFO:root:loaded params...
{   'data': {   'dataset_test': '/home/gridsan/nchutisilp/projects/ModelsGenesis/notebooks/tabular_data/cf_pres_test.csv',
                'dataset_train': '/home/gridsan/nchutisilp/projects/ModelsGenesis/notebooks/tabular_data/cf_pres_train_fold1.csv',
                'dataset_type': 'VideoDataset',
                'dataset_val': '/home/gridsan/nchutisilp/projects/ModelsGenesis/notebooks/tabular_data/cf_pres_val_fold1.csv',
                'frame_step': 3,
                'frames_per_clip': 128,
                'num_classes': 2,
                'num_segments': 1,
                'num_views_per_segment': 1},
    'eval_name': 'video_classification_frozen',
    'nodes': 8,
    'optimization': {   'attend_across_segments': True,
                        'batch_size': 2,
                        'final_lr': 0.0,
                        'freeze_encoder': False,
                        'lr': 0.001,
                        'num_epochs': 150,
                        'resolution': 224,
                        'start_lr': 0.001,
                        'use_bfloat16': True,
                        'warmup': 0.0,
                        'weight_decay': 0.01},
    'pretrain': {   'checkpoint': 'jepa-latest.pth.tar',
                    'checkpoint_key': 'target_encoder',
                    'clip_duration': None,
                    'folder': '/home/gridsan/nchutisilp/projects/jepa/pretrain_models',
                    'frames_per_clip': 16,
                    'model_name': 'vit_large',
                    'patch_size': 16,
                    'tight_silu': False,
                    'tubelet_size': 2,
                    'uniform_power': True,
                    'use_sdpa': True,
                    'use_silu': False,
                    'write_tag': 'jepa'},
    'resume_checkpoint': True,
    'tag': 'cf-pres-from-vjepa-16x2x3-fold1',
    'tasks_per_node': 8}
Random port is ... 15491
INFO:root:Running... (rank: 0/1)
INFO:root:Running evaluation: video_classification_frozen
INFO:root:Initialized (rank/world-size) 0/1
INFO:root:Loading pretrained model from /home/gridsan/nchutisilp/projects/jepa/pretrain_models/jepa-latest.pth.tar
VisionTransformer(
  (patch_embed): PatchEmbed3D(
    (proj): Conv3d(3, 1024, kernel_size=(2, 16, 16), stride=(2, 16, 16))
  )
  (blocks): ModuleList(
    (0-23): 24 x Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
)
INFO:root:loaded pretrained model with msg: <All keys matched successfully>
INFO:root:loaded pretrained encoder from epoch: 300
 path: /home/gridsan/nchutisilp/projects/jepa/pretrain_models/jepa-latest.pth.tar
INFO:root:VideoDataset dataset created
INFO:root:VideoDataset unsupervised data loader created
INFO:root:VideoDataset dataset created
INFO:root:VideoDataset unsupervised data loader created
INFO:root:Dataloader created... iterations per epoch: 53
INFO:root:Unfreezing encoder...
INFO:root:Using AdamW
INFO:root:loaded best validation dice from epoch 150 with f1: 0.8695651888847351
INFO:root:loaded pretrained encoder from epoch 150 with msg: <All keys matched successfully>
INFO:root:loaded pretrained classifier from epoch 150 with msg: <All keys matched successfully>
INFO:root:loaded optimizers from epoch 150
INFO:root:read-path: /home/gridsan/nchutisilp/projects/jepa/pretrain_models/video_classification_frozen/cf-pres-from-vjepa-16x2x3-fold1/jepa-latest.pth.tar
INFO:root:VideoDataset dataset created
INFO:root:VideoDataset unsupervised data loader created
INFO:root:loaded best validation dice from epoch 2 with f1: 0.8695651888847351
INFO:root:loaded pretrained encoder from epoch 2 with msg: <All keys matched successfully>
INFO:root:loaded pretrained classifier from epoch 2 with msg: <All keys matched successfully>
INFO:root:loaded optimizers from epoch 2
INFO:root:read-path: /home/gridsan/nchutisilp/projects/jepa/pretrain_models/video_classification_frozen/cf-pres-from-vjepa-16x2x3-fold1/jepa-best.pth.tar
/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/backends/cuda/__init__.py:342: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
outputs torch.Size([2]) tensor([1, 1], device='cuda:0')
labels torch.Size([2]) tensor([1, 1], device='cuda:0')
Validation min-max: tensor(0.) tensor(1.)
Validation Output torch.Size([2]) tensor([3.9338e-10, 1.0000e+00], device='cuda:0')
Validation Output torch.Size([2]) tensor([3.9032e-10, 1.0000e+00], device='cuda:0')
Validation Labels torch.Size([2]) tensor([1, 1], device='cuda:0')
INFO:root:[    0] 100.000% (loss: 0.000) [mem: 6.09e+03]
outputs torch.Size([2]) tensor([1, 1], device='cuda:0')
labels torch.Size([2]) tensor([0, 1], device='cuda:0')
Validation min-max: tensor(0.) tensor(1.)
Validation Output torch.Size([2]) tensor([3.9032e-10, 1.0000e+00], device='cuda:0')
Validation Output torch.Size([2]) tensor([3.9338e-10, 1.0000e+00], device='cuda:0')
Validation Labels torch.Size([2]) tensor([0, 1], device='cuda:0')
outputs torch.Size([2]) tensor([1, 1], device='cuda:0')
labels torch.Size([2]) tensor([1, 1], device='cuda:0')
Validation min-max: tensor(0.) tensor(1.)
Validation Output torch.Size([2]) tensor([4.0587e-10, 1.0000e+00], device='cuda:0')
Validation Output torch.Size([2]) tensor([3.9957e-10, 1.0000e+00], device='cuda:0')
Validation Labels torch.Size([2]) tensor([1, 1], device='cuda:0')
outputs torch.Size([2]) tensor([1, 1], device='cuda:0')
labels torch.Size([2]) tensor([0, 1], device='cuda:0')
Validation min-max: tensor(0.) tensor(1.)
Validation Output torch.Size([2]) tensor([3.9646e-10, 1.0000e+00], device='cuda:0')
Validation Output torch.Size([2]) tensor([3.9338e-10, 1.0000e+00], device='cuda:0')
Validation Labels torch.Size([2]) tensor([0, 1], device='cuda:0')
outputs torch.Size([2]) tensor([1, 1], device='cuda:0')
labels torch.Size([2]) tensor([1, 1], device='cuda:0')
Validation min-max: tensor(0.) tensor(1.)
Validation Output torch.Size([2]) tensor([3.8427e-10, 1.0000e+00], device='cuda:0')
Validation Output torch.Size([2]) tensor([3.9957e-10, 1.0000e+00], device='cuda:0')
Validation Labels torch.Size([2]) tensor([1, 1], device='cuda:0')
outputs torch.Size([2]) tensor([1, 1], device='cuda:0')
labels torch.Size([2]) tensor([1, 1], device='cuda:0')
Validation min-max: tensor(0.) tensor(1.)
Validation Output torch.Size([2]) tensor([3.9338e-10, 1.0000e+00], device='cuda:0')
Validation Output torch.Size([2]) tensor([3.9032e-10, 1.0000e+00], device='cuda:0')
Validation Labels torch.Size([2]) tensor([1, 1], device='cuda:0')
outputs torch.Size([2]) tensor([1, 1], device='cuda:0')
labels torch.Size([2]) tensor([1, 0], device='cuda:0')
Validation min-max: tensor(0.) tensor(1.)
Validation Output torch.Size([2]) tensor([3.9338e-10, 1.0000e+00], device='cuda:0')
Validation Output torch.Size([2]) tensor([3.9338e-10, 1.0000e+00], device='cuda:0')
Validation Labels torch.Size([2]) tensor([1, 0], device='cuda:0')
outputs torch.Size([2]) tensor([1, 1], device='cuda:0')
labels torch.Size([2]) tensor([1, 1], device='cuda:0')
Validation min-max: tensor(0.) tensor(1.)
Validation Output torch.Size([2]) tensor([3.9338e-10, 1.0000e+00], device='cuda:0')
Validation Output torch.Size([2]) tensor([3.9338e-10, 1.0000e+00], device='cuda:0')
Validation Labels torch.Size([2]) tensor([1, 1], device='cuda:0')
outputs torch.Size([2]) tensor([1, 1], device='cuda:0')
labels torch.Size([2]) tensor([1, 0], device='cuda:0')
Validation min-max: tensor(0.) tensor(1.)
Validation Output torch.Size([2]) tensor([3.8728e-10, 1.0000e+00], device='cuda:0')
Validation Output torch.Size([2]) tensor([4.0905e-10, 1.0000e+00], device='cuda:0')
Validation Labels torch.Size([2]) tensor([1, 0], device='cuda:0')
outputs torch.Size([2]) tensor([1, 1], device='cuda:0')
labels torch.Size([2]) tensor([1, 1], device='cuda:0')
Validation min-max: tensor(0.) tensor(1.)
Validation Output torch.Size([2]) tensor([3.9338e-10, 1.0000e+00], device='cuda:0')
Validation Output torch.Size([2]) tensor([3.9338e-10, 1.0000e+00], device='cuda:0')
Validation Labels torch.Size([2]) tensor([1, 1], device='cuda:0')
outputs torch.Size([2]) tensor([1, 1], device='cuda:0')
labels torch.Size([2]) tensor([0, 0], device='cuda:0')
Validation min-max: tensor(0.) tensor(1.)
Validation Output torch.Size([2]) tensor([3.9338e-10, 1.0000e+00], device='cuda:0')
Validation Output torch.Size([2]) tensor([3.9338e-10, 1.0000e+00], device='cuda:0')
Validation Labels torch.Size([2]) tensor([0, 0], device='cuda:0')
outputs torch.Size([2]) tensor([1, 1], device='cuda:0')
labels torch.Size([2]) tensor([1, 1], device='cuda:0')
Validation min-max: tensor(0.) tensor(1.)
Validation Output torch.Size([2]) tensor([3.9338e-10, 1.0000e+00], device='cuda:0')
Validation Output torch.Size([2]) tensor([3.9646e-10, 1.0000e+00], device='cuda:0')
Validation Labels torch.Size([2]) tensor([1, 1], device='cuda:0')
outputs torch.Size([2]) tensor([1, 1], device='cuda:0')
labels torch.Size([2]) tensor([0, 0], device='cuda:0')
Validation min-max: tensor(0.) tensor(1.)
Validation Output torch.Size([2]) tensor([3.9646e-10, 1.0000e+00], device='cuda:0')
Validation Output torch.Size([2]) tensor([3.9646e-10, 1.0000e+00], device='cuda:0')
Validation Labels torch.Size([2]) tensor([0, 0], device='cuda:0')
outputs torch.Size([2]) tensor([1, 1], device='cuda:0')
labels torch.Size([2]) tensor([0, 1], device='cuda:0')
Validation min-max: tensor(0.) tensor(1.)
Validation Output torch.Size([2]) tensor([3.9646e-10, 1.0000e+00], device='cuda:0')
Validation Output torch.Size([2]) tensor([3.9338e-10, 1.0000e+00], device='cuda:0')
Validation Labels torch.Size([2]) tensor([0, 1], device='cuda:0')
outputs torch.Size([2]) tensor([1, 1], device='cuda:0')
labels torch.Size([2]) tensor([0, 1], device='cuda:0')
Validation min-max: tensor(0.) tensor(1.)
Validation Output torch.Size([2]) tensor([3.9338e-10, 1.0000e+00], device='cuda:0')
Validation Output torch.Size([2]) tensor([3.9646e-10, 1.0000e+00], device='cuda:0')
Validation Labels torch.Size([2]) tensor([0, 1], device='cuda:0')
outputs torch.Size([2]) tensor([1, 1], device='cuda:0')
labels torch.Size([2]) tensor([0, 1], device='cuda:0')
Validation min-max: tensor(0.) tensor(1.)
Validation Output torch.Size([2]) tensor([4.0271e-10, 1.0000e+00], device='cuda:0')
Validation Output torch.Size([2]) tensor([3.9338e-10, 1.0000e+00], device='cuda:0')
Validation Labels torch.Size([2]) tensor([0, 1], device='cuda:0')
outputs torch.Size([1]) tensor([1], device='cuda:0')
labels torch.Size([1]) tensor([0], device='cuda:0')
Validation min-max: tensor(0.) tensor(1.)
Validation Output torch.Size([2]) tensor([3.9338e-10, 1.0000e+00], device='cuda:0')
Validation Labels torch.Size([1]) tensor([0], device='cuda:0')
[Label/Prediction] Validation zeros: 12 / 0, Training ones: 21 / 33
INFO:root:Test Accuracy: 0.63636, Precision: 0.63636, Recall: 1.00000, F1: 0.77778
