/home/gridsan/nchutisilp/.conda/envs/jepa/bin/python
INFO:root:called-params configs/evals/vitl16_cf_pres_16x2x3_frozen_from_vjepa.yaml
INFO:root:loaded params...
{   'data': {   'dataset_test': '/home/gridsan/nchutisilp/projects/ModelsGenesis/notebooks/tabular_data/cf_pres_test.csv',
                'dataset_train': '/home/gridsan/nchutisilp/projects/ModelsGenesis/notebooks/tabular_data/cf_pres_train_fold0.csv',
                'dataset_type': 'VideoDataset',
                'dataset_val': '/home/gridsan/nchutisilp/projects/ModelsGenesis/notebooks/tabular_data/cf_pres_val_fold0.csv',
                'frame_step': 2,
                'frames_per_clip': 186,
                'num_classes': 2,
                'num_segments': 1,
                'num_views_per_segment': 1},
    'eval_name': 'video_classification_frozen',
    'nodes': 8,
    'optimization': {   'attend_across_segments': True,
                        'batch_size': 24,
                        'final_lr': 0.0,
                        'freeze_encoder': True,
                        'lr': 0.001,
                        'num_epochs': 150,
                        'resolution': 224,
                        'start_lr': 0.001,
                        'use_bfloat16': True,
                        'warmup': 0.0,
                        'weight_decay': 0.01},
    'pretrain': {   'checkpoint': 'jepa-latest.pth.tar',
                    'checkpoint_key': 'target_encoder',
                    'clip_duration': None,
                    'folder': '/home/gridsan/nchutisilp/projects/jepa/pretrain_models',
                    'frames_per_clip': 16,
                    'model_name': 'vit_large',
                    'patch_size': 16,
                    'tight_silu': False,
                    'tubelet_size': 2,
                    'uniform_power': True,
                    'use_sdpa': True,
                    'use_silu': False,
                    'write_tag': 'jepa'},
    'resume_checkpoint': True,
    'tag': 'cf-pres-from-vjepa-16x2x3-fold0',
    'tasks_per_node': 8}
Random port is ... 50033
INFO:root:Running... (rank: 0/1)
INFO:root:Running evaluation: video_classification_frozen
INFO:root:Initialized (rank/world-size) 0/1
INFO:root:Loading pretrained model from /home/gridsan/nchutisilp/projects/jepa/pretrain_models/jepa-latest.pth.tar
VisionTransformer(
  (patch_embed): PatchEmbed3D(
    (proj): Conv3d(3, 1024, kernel_size=(2, 16, 16), stride=(2, 16, 16))
  )
  (blocks): ModuleList(
    (0-23): 24 x Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
)
INFO:root:loaded pretrained model with msg: <All keys matched successfully>
INFO:root:loaded pretrained encoder from epoch: 300
 path: /home/gridsan/nchutisilp/projects/jepa/pretrain_models/jepa-latest.pth.tar
INFO:root:VideoDataset dataset created
INFO:root:VideoDataset unsupervised data loader created
INFO:root:VideoDataset dataset created
INFO:root:VideoDataset unsupervised data loader created
INFO:root:Dataloader created... iterations per epoch: 5
INFO:root:Using AdamW
INFO:root:loaded best validation dice from epoch 150 with f1: 0.9047619104385376
INFO:root:loaded pretrained encoder from epoch 150 with msg: <All keys matched successfully>
INFO:root:loaded pretrained classifier from epoch 150 with msg: <All keys matched successfully>
INFO:root:loaded optimizers from epoch 150
INFO:root:read-path: /home/gridsan/nchutisilp/projects/jepa/pretrain_models/video_classification_frozen/cf-pres-from-vjepa-16x2x3-fold0/jepa-latest.pth.tar
INFO:root:VideoDataset dataset created
INFO:root:VideoDataset unsupervised data loader created
INFO:root:loaded best validation dice from epoch 85 with f1: 0.9047619104385376
INFO:root:loaded pretrained encoder from epoch 85 with msg: <All keys matched successfully>
INFO:root:loaded pretrained classifier from epoch 85 with msg: <All keys matched successfully>
INFO:root:loaded optimizers from epoch 85
INFO:root:read-path: /home/gridsan/nchutisilp/projects/jepa/pretrain_models/video_classification_frozen/cf-pres-from-vjepa-16x2x3-fold0/jepa-best.pth.tar
/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/backends/cuda/__init__.py:342: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
outputs torch.Size([24]) tensor([1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0],
       device='cuda:0')
labels torch.Size([24]) tensor([1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1],
       device='cuda:0')
Validation min-max: tensor(0.) tensor(1.)
Validation Output torch.Size([2]) tensor([0.1205, 0.8795], device='cuda:0')
Validation Output torch.Size([2]) tensor([0.4244, 0.5756], device='cuda:0')
Validation Output torch.Size([2]) tensor([0.0677, 0.9323], device='cuda:0')
Validation Output torch.Size([2]) tensor([0.0281, 0.9719], device='cuda:0')
Validation Output torch.Size([2]) tensor([0.5001, 0.4999], device='cuda:0')
Validation Output torch.Size([2]) tensor([0.5146, 0.4854], device='cuda:0')
Validation Output torch.Size([2]) tensor([0.5922, 0.4078], device='cuda:0')
Validation Output torch.Size([2]) tensor([0.0110, 0.9890], device='cuda:0')
Validation Output torch.Size([2]) tensor([0.4509, 0.5491], device='cuda:0')
Validation Output torch.Size([2]) tensor([0.0029, 0.9971], device='cuda:0')
Validation Output torch.Size([2]) tensor([0.2528, 0.7472], device='cuda:0')
Validation Output torch.Size([2]) tensor([0.1934, 0.8066], device='cuda:0')
Validation Output torch.Size([2]) tensor([0.0125, 0.9875], device='cuda:0')
Validation Output torch.Size([2]) tensor([0.0425, 0.9575], device='cuda:0')
Validation Output torch.Size([2]) tensor([0.2102, 0.7898], device='cuda:0')
Validation Output torch.Size([2]) tensor([0.0168, 0.9832], device='cuda:0')
Validation Output torch.Size([2]) tensor([0.4238, 0.5762], device='cuda:0')
Validation Output torch.Size([2]) tensor([5.9418e-04, 9.9941e-01], device='cuda:0')
Validation Output torch.Size([2]) tensor([0.0070, 0.9930], device='cuda:0')
Validation Output torch.Size([2]) tensor([0.0011, 0.9989], device='cuda:0')
Validation Output torch.Size([2]) tensor([0.7825, 0.2175], device='cuda:0')
Validation Output torch.Size([2]) tensor([0.0679, 0.9321], device='cuda:0')
Validation Output torch.Size([2]) tensor([0.0082, 0.9918], device='cuda:0')
Validation Output torch.Size([2]) tensor([0.9476, 0.0524], device='cuda:0')
Validation Labels torch.Size([24]) tensor([1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1],
       device='cuda:0')
INFO:root:[    0] 70.833% (loss: 0.990) [mem: 1.77e+04]
outputs torch.Size([9]) tensor([1, 1, 1, 1, 0, 1, 1, 1, 1], device='cuda:0')
labels torch.Size([9]) tensor([0, 0, 0, 1, 0, 1, 0, 1, 0], device='cuda:0')
Validation min-max: tensor(0.) tensor(1.)
Validation Output torch.Size([2]) tensor([0.0249, 0.9751], device='cuda:0')
Validation Output torch.Size([2]) tensor([0.4949, 0.5051], device='cuda:0')
Validation Output torch.Size([2]) tensor([0.3863, 0.6137], device='cuda:0')
Validation Output torch.Size([2]) tensor([0.1058, 0.8942], device='cuda:0')
Validation Output torch.Size([2]) tensor([0.5853, 0.4147], device='cuda:0')
Validation Output torch.Size([2]) tensor([0.4320, 0.5680], device='cuda:0')
Validation Output torch.Size([2]) tensor([0.0034, 0.9966], device='cuda:0')
Validation Output torch.Size([2]) tensor([0.1427, 0.8573], device='cuda:0')
Validation Output torch.Size([2]) tensor([0.0061, 0.9939], device='cuda:0')
Validation Labels torch.Size([9]) tensor([0, 0, 0, 1, 0, 1, 0, 1, 0], device='cuda:0')
[Label/Prediction] Validation zeros: 12 / 6, Training ones: 21 / 27
INFO:root:Test Accuracy: 0.63636, Precision: 0.66667, Recall: 0.85714, F1: 0.75000
